# Task 4.7: Sensitive Content Detection — `detectSensitiveContent`

## Summary

Created `lib/ai/sensitive-content.ts` — a lightweight, keyword-based module that detects safeguarding concerns, suicidal ideation in client context, and therapist distress patterns in therapist messages. This completes the final safety-critical item in Phase 4.

## Files created

### `lib/ai/sensitive-content.ts`

Exports:

- **`detectSensitiveContent(message)`** — Main function. Takes a therapist's message string and returns a `SensitiveContentDetection` with detected categories, additional LLM instructions, and auto-search queries.
- **Types:** `SensitiveCategory`, `SensitiveContentDetection`, `AutoSearchQuery`

### `lib/ai/__tests__/sensitive-content.test.ts`

67 test cases covering:
- All three detection categories with multiple keyword/phrase variations
- Multi-category simultaneous detection
- Case insensitivity
- Whitespace normalisation (line breaks, tabs, extra spaces)
- Word boundary matching
- Return shape validation
- Edge cases (empty input, null/undefined, very long messages, special characters)
- Accepted false positives (academic/research context triggers are by design)

## Detection categories

### 1. Safeguarding (`safeguarding`)

**Triggers:** "safeguarding", "disclosure", "abuse", "neglect", "child protection", "harm to children", "duty to report", "vulnerable adult", "domestic violence", "modern slavery", "FGM", "trafficking", "grooming", "elder abuse", "children act", "care act"

**Instructions include:**
- Reference statutory obligations under Children Act 2004 and Care Act 2014
- Verbatim safety statement about safeguarding precedence over confidentiality
- Direction to organisation's safeguarding lead

**Auto-searches:**
- `searchLegislation`: "Children Act 2004 safeguarding duties"
- `searchLegislation`: "Care Act 2014 adult safeguarding"

### 2. Suicidal ideation (`suicidal_ideation`)

**Triggers:** "suicidal", "suicide", "self-harm", "overdose", "wants to end their life", "client mentioned dying", "risk assessment", "safety plan", "risk to self", "not wanting to be here", "thoughts of death"

**Instructions include:**
- Reference risk assessment frameworks (but NEVER assess risk)
- Verbatim statement about risk assessment being a clinical responsibility
- Encourage documentation and supervisor discussion

**Auto-searches:**
- `searchGuidelines`: "risk assessment framework suicide self-harm"

### 3. Therapist distress (`therapist_distress`)

**Triggers:** "I'm struggling", "burnt out", "burnout", "can't cope", "vicarious trauma", "compassion fatigue", "emotionally exhausted", "dreading sessions", "secondary trauma"

**Instructions include:**
- Validate the therapist's experience
- Suggest supervision and self-care
- Do NOT provide therapy to the therapist

**Auto-searches:**
- `searchGuidelines`: "therapist self-care supervision wellbeing compassion fatigue"

## Design decisions

### Two matching strategies

- **Single keywords** use `\b` word-boundary regex to prevent false matches inside unrelated words while still catching the keyword in any position
- **Multi-word phrases** use simple substring matching on the normalised (lowercased, whitespace-collapsed) message

### Broad pattern set for safety

The keyword/phrase lists go beyond the spec's minimum examples. For safeguarding, this includes "trafficking", "FGM", "county lines", "modern slavery", and other UK-relevant concerns. For suicidal ideation, it includes gendered variants ("ending his/her/their life") and colloquial expressions ("not wanting to be here"). This follows the principle that false positives are acceptable but false negatives are not.

### Structured auto-search queries

Rather than returning bare query strings, each auto-search specifies both the tool name and query. This lets the chat route dispatch to the correct tool without parsing the query content.

### Deterministic ordering

Categories are always checked in the same order (safeguarding → suicidal_ideation → therapist_distress), so the `detectedCategories` array has a predictable ordering when multiple categories trigger.

### No LLM involvement

The entire module is pure string matching — no embeddings, no API calls. It runs in < 1ms on typical messages and has zero external dependencies.

## Integration point

`detectSensitiveContent` should be called in the chat route before or alongside tool invocation. The typical integration:

```ts
import { detectSensitiveContent } from "@/lib/ai/sensitive-content";

// In the chat route, before streamText:
const lastMessage = messages[messages.length - 1];
const sensitive = detectSensitiveContent(lastMessage.content);

if (sensitive.detectedCategories.length > 0) {
  // 1. Append additionalInstructions to the system prompt
  // 2. Auto-trigger the searches in sensitive.autoSearchQueries
}
```

The `autoSearchQueries` array contains `{ tool, query }` objects that map directly to the registered search tools (`searchLegislation`, `searchGuidelines`). These can be invoked programmatically before or alongside the LLM's own tool calls.

## Current RAG pipeline status

| Task | Status |
|------|--------|
| 4.1 Base KB search tool | ✅ |
| 4.2 Domain-specific tools | ✅ |
| 4.3 Clinical system prompt | ✅ |
| 4.4 Confidence thresholds | ✅ |
| 4.5 Integrate tools into chat route | ✅ |
| 4.6 No-results handling | ✅ |
| 4.7 Sensitive content detection | ✅ |

**Phase 4 is now complete.** All safety-critical items (4.4, 4.6, 4.7) are implemented. The remaining work before therapist testing is:
1. Content authoring (Phase 2 — Aaron)
2. Integration of 4.4 into the tool files (prompt exists in `confidence-integration-guide.md`)
3. Wiring 4.7 into the chat route
4. Therapist profile UI
