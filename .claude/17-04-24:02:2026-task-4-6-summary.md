# Task 4.6: No-Results Handling — `buildContextualResponse`

## Summary

Created `lib/ai/contextual-response.ts` — a utility that takes confidence-assessed search results (from Task 4.4's `applyConfidenceThreshold`) and formats them into an XML context string for LLM injection. This completes the second of three safety-critical items.

## File created

### `lib/ai/contextual-response.ts`

Exports:

- **`buildContextualResponse(options)`** — Main function. Takes a confidence tier, filtered results, and optional modality. Returns a `ContextualResponse` with the formatted context string.
- **`MAX_CONTEXT_CHUNKS = 5`** — Configurable cap on injected chunks (spec allows 3–5).
- **Types:** `ContextChunk`, `BuildContextualResponseOptions`, `ContextualResponse`

### `lib/ai/__tests__/contextual-response.test.ts`

22 test cases covering:
- All three confidence tiers (high, moderate, low)
- XML structure and attribute formatting
- Hedging preamble placement for moderate tier
- Modality-aware supervisor referral for low tier
- camelCase ↔ snake_case field normalisation (domain vs base tools)
- Edge cases: empty results on high tier, XML escaping, maxChunks override

## Design decisions

### XML format matches the spec exactly

```xml
<context>
<document id="1" title="BACP Ethical Framework" section="Principle of Fidelity">
[chunk content]
</document>
</context>
```

- `id` is a sequential 1-based index (not the database ID) — simpler for the LLM to reference in citations
- `section` attribute omitted when null rather than showing empty string
- Title and section are XML-escaped; chunk content is not (it's consumed by the LLM, not an XML parser)

### Field name normalisation

The function accepts chunks from both tool shapes without requiring the caller to normalise first:
- Domain tools (`knowledge-search-tools.ts`): `documentTitle`, `sectionPath`, `similarityScore`
- Base tool (`search-knowledge-base.ts`): `document_title`, `section_path`, `similarity_score`

### Defensive degradation

If `buildContextualResponse` receives a "high" or "moderate" tier but an empty results array (shouldn't happen if 4.4 is working, but defense in depth), it falls back to the low-confidence supervisor referral.

### Modality-aware low-confidence message

The low tier message includes the therapist's modality when available:
- With modality: "...general therapeutic principles for CBT practice..."
- Without: "...general therapeutic principles for the therapist's modality..."

## Integration point

`buildContextualResponse` is called after `applyConfidenceThreshold` and before the context is injected into the LLM prompt. The typical call site is wherever tool results are assembled into the prompt context — likely in the chat route or a prompt-building utility:

```ts
import { applyConfidenceThreshold } from "@/lib/ai/confidence";
import { buildContextualResponse } from "@/lib/ai/contextual-response";

// After a search tool returns results:
const assessed = applyConfidenceThreshold(searchResults);
const { contextString, chunksInjected, confidenceTier } = buildContextualResponse({
  confidenceTier: assessed.confidenceTier,
  results: assessed.results,
  modality: therapistProfile?.defaultModality,
});

// contextString is then injected into the LLM's context
```

**Note:** Whether `buildContextualResponse` is called inside each tool's `execute` function or in the chat route depends on the integration pattern. Since the Vercel AI SDK's tool-based retrieval means the LLM sees tool results directly, this function is most useful when:
1. Building a system prompt supplement from tool results (multi-step pattern)
2. Or as a formatting layer the LLM instructions reference

For the current tool-based architecture, the confidence tier and note are already returned as structured fields by the tools (per Task 4.4). The XML formatting in `buildContextualResponse` is most relevant if you later add a pre-fetch path or need to format aggregated multi-tool results into a single context block.

## Current RAG pipeline status

| Task | Status |
|------|--------|
| 4.1 Base KB search tool | ✅ |
| 4.2 Domain-specific tools | ✅ |
| 4.3 Clinical system prompt | ✅ |
| 4.4 Confidence thresholds | ✅ |
| 4.5 Integrate tools into chat route | ✅ |
| 4.6 No-results handling | ✅ |
| 4.7 Sensitive content detection | ❌ — final safety-critical item |
